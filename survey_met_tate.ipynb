{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139746d-39c2-4f01-b6f6-40ede375e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.abspath('queries'))\n",
    "from queries import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673edaa0-b05e-4093-859c-410fad972479",
   "metadata": {},
   "source": [
    "# Met\n",
    "source: csv file. We read it as pandas dataframe, count how many ids with the desired characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eebb3d0-b0f4-44b4-9d92-1db415385c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_path = \"downloaded-data/MetObjects.txt\"\n",
    "met_df = pd.read_csv(met_path, delimiter=',', dtype=str)\n",
    "met_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e89d61-b0ea-4193-9605-a946790d63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"Object Number\", \"Culture\", \"Period\", \"Dynasty\", \"Reign\", \"Object Date\", \"Object Begin Date\", \"Object End Date\", \"Artist Alpha Sort\", \"Artist Nationality\", \"Artist Begin Date\", \"Artist End Date\", \"Object Wikidata URL\", \"Artist ULAN URL\", \"Artist Wikidata URL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fab28b-c93b-4b0b-bbc0-5d9faccc06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = met_df[columns_to_keep]\n",
    "duplicated_mask = filtered_df['Object Number'].duplicated(keep=False)\n",
    "\n",
    "# Invert the mask to keep only unique values\n",
    "unique_values_df = filtered_df[~duplicated_mask]\n",
    "unique_values_df = unique_values_df.replace(\"NaN\", \" \")\n",
    "unique_values_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdfb62f-9cee-456d-8948-6a4471991c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total number of artworks by counting the ids\n",
    "met_art_tot = unique_values_df[\"Object Number\"].notna().sum() - (unique_values_df[\"Object Number\"] == '').sum()\n",
    "print(met_art_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75bd4e-4af6-4c56-98a4-15b73657f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column groups of each filed of interest (date, artist, artist dates, artworks aligned, authors aligned)\n",
    "date_columns = [\"Object Date\", \"Object Begin Date\", \"Object End Date\"]\n",
    "artist_columns = [\"Artist Alpha Sort\"]\n",
    "artist_date_columns = [\"Artist Begin Date\", \"Artist End Date\"]\n",
    "art_aligned = [\"Object Wikidata URL\"]\n",
    "artist_aligned_columns = [\"Artist ULAN URL\", \"Artist Wikidata URL\"]\n",
    "\n",
    "# Function to count non-empty cells\n",
    "def count_non_empty(df, columns):\n",
    "    return df[columns].notna().sum(axis=1).gt(0).sum()\n",
    "\n",
    "# Count non-empty cells in each group\n",
    "date_tot = count_non_empty(unique_values_df, date_columns)\n",
    "artist_tot = count_non_empty(unique_values_df, artist_columns)\n",
    "artist_date_tot = count_non_empty(unique_values_df, artist_date_columns)\n",
    "art_aligned_tot = count_non_empty(unique_values_df, art_aligned)\n",
    "artist_aligned_tot = count_non_empty(unique_values_df, artist_aligned_columns)\n",
    "\n",
    "#print(f\"date_tot: {date_tot}, artist_tot: {artist_tot}, artist_date_tot: {artist_date_tot}, aligned_tot: {art_aligned_tot}\")\n",
    "\n",
    "res_list = [\"Metropolitan\", int(met_art_tot), int(date_tot), 0, 0, int(artist_tot), int(artist_date_tot), 0, int(art_aligned_tot), int(artist_aligned_tot)]\n",
    "prop_list = make_prop_list(res_list)\n",
    "print(res_list)\n",
    "print(prop_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e9cdb-9a43-4cf5-8306-2736e96ebe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Dataset', 'Artworks', 'With date', 'With place', 'With date and place', 'With author', 'With author with date', 'With author with place','With artworks aligned to Wikidata', 'With author aligned to Wikidata or Ulan']\n",
    "headers_prop = headers.copy()\n",
    "headers_prop.remove('Artworks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a2402-92b5-4226-aac6-d47dbb92ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "with open('met_res.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerow(res_list)\n",
    "with open('met_res_prop.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(headers_prop)\n",
    "    writer.writerow(prop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1bf62f-6b09-4e03-907c-1b04cb0c7ee7",
   "metadata": {},
   "source": [
    "# Tate\n",
    "The Tate API limits the number of results. For this reason, we downloaded the dataset available at [https://github.com/tategallery/collection/tree/master](https://github.com/tategallery/collection/tree/master). Nevertheless, this dataset is not maintained anymore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91133318-45d3-4e3e-84e8-be1a2bd6571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify null values (entry, with not known/negative entry)\n",
    "null_values = [\"date not known\", \"None\", \"null\", \"Null\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51735d1-5666-4f84-ae0b-4fce180fbca5",
   "metadata": {},
   "source": [
    "Extraction of the artists having a date, a place or both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f55bea-ec6b-4edb-bae9-113b51ac4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the json files organized in folders\n",
    "def artist_date_place(base_path):\n",
    "    with_date = set()\n",
    "    with_place = set()\n",
    "    count_files = 0\n",
    "    files_crashed = 0\n",
    "    # Traverse the directory structure\n",
    "\n",
    "    start = time.time()\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                count_files+=1\n",
    "                try:\n",
    "                    with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                        data = json.load(f)\n",
    "                        # Check if there is the id: \n",
    "                        if \"id\" in data and str(data['id']) not in null_values: \n",
    "                            artist_id = data['id']\n",
    "                            artist_name = data['fc']\n",
    "                            #print(\"------------artist: \", artist_name, artist_id)\n",
    "                            # set details presence to None\n",
    "                            date_info = None\n",
    "                            place_info = None\n",
    "                            if 'birth' in data: \n",
    "                                if 'place' in data['birth']:\n",
    "                                    birth_place = data['birth']['place']\n",
    "                                    if 'name' in birth_place and str(birth_place['name']) not in null_values:\n",
    "                                       # print(\"birth place: \", birth_place['name'])\n",
    "                                        place_info = True\n",
    "                                if 'time' in data['birth']: \n",
    "                                    birth_time = data['birth']['time']\n",
    "                                    if 'startYear' in birth_time and str(birth_time['startYear']) not in null_values: \n",
    "                                        date_info = True\n",
    "    \n",
    "                            if place_info == None and 'death' in data: \n",
    "                                if 'place' in data['death']:\n",
    "                                    death_place = data['death']['place']\n",
    "                                    if 'name' in death_place and str(death_place['name']) not in null_values:\n",
    "                                       # print(\"death place: \", death_place['name'])\n",
    "                                        place_info = True\n",
    "                                        \n",
    "                            if 'activePlaces' in data:\n",
    "                                for d in data['activePlaces']:\n",
    "                                    if place_info == None: \n",
    "                                        if 'name' in d and d['name'] not in null_values:\n",
    "                                            place_info = True\n",
    "                                        \n",
    "                            if \"date\" in data and str(data[\"date\"]) not in null_values: \n",
    "                               # print(\"date: \", data[\"date\"])\n",
    "                                date_info = True\n",
    "                            \n",
    "                                \n",
    "                            # add artists with details to the respective set\n",
    "                            if place_info == True: \n",
    "                                with_place.add(artist_id) \n",
    "                            if date_info == True: \n",
    "                                with_date.add(artist_id)                           \n",
    "                                \n",
    "                except Exception as e: \n",
    "                    print(f\"Error reading {file}: {e}\")\n",
    "                    files_crashed+=1\n",
    "                    \n",
    "                print(\"files processed: \", count_files)\n",
    "    end = time.time()\n",
    "    print(\"tot files processed: \", count_files, \"tot files crashed: \", files_crashed)\n",
    "    print(\"tot artists with date: \", len(with_date), \"tot artists with place: \", len(with_place))\n",
    "\n",
    "    t = end -start\n",
    "    print(\"Total time: \", t)\n",
    "    return with_place, with_date\n",
    "\n",
    "artists_path = \"downloaded-data/collection-master/artists\"\n",
    "artist_test_path = \"downloaded-data/collection-master/artists/b\"\n",
    "\n",
    "\n",
    "# Count the total number of artworks\n",
    "artists_with_place, artists_with_date = artist_date_place(artists_path)\n",
    "\n",
    "print(artists_with_place)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c70ac-f1a7-4be2-98e1-4a05afa1bb12",
   "metadata": {},
   "source": [
    "We query the artworks files. We check whether they have further infomation about date and place, and if the author is part of the previously created lists. We count how many artworks have one or more of these aspects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6648a5a-6d53-45ff-bb64-c25fed1a9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_artworks(base_path):\n",
    "    artwork_count = 0\n",
    "    tate_art_date_count = 0\n",
    "    tate_art_place_count = 0\n",
    "    tate_artist_count = 0\n",
    "    tate_artist_date_count = 0\n",
    "    tate_artist_place_count = 0\n",
    "\n",
    "    start = time.time()\n",
    "    count_files = 0\n",
    "    files_crashed = 0\n",
    "    # Traverse the directory structure\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        tate_artwork_count = 0\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                count_files +=1\n",
    "                art_has_auth_place = None\n",
    "                art_has_auth_date = None\n",
    "                try:\n",
    "                    with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                        data = json.load(f)\n",
    "                        # Check if it's an artwork file\n",
    "                        if 'id' in data and 'title' in data:\n",
    "                          #  print(\"---------- Artwork: \", data[\"title\"], data[\"id\"])\n",
    "                            artwork_count += 1\n",
    "                        if 'dateText' in data and str(data['dateText']) not in null_values: \n",
    "                           # print(\"artwork date: \", data['dateText'])\n",
    "                            tate_art_date_count+=1\n",
    "                        if 'all_artists' in data and str(data['all_artists']) not in null_values:\n",
    "                            tate_artist_count+=1\n",
    "                            artist_details = data['contributors']\n",
    "\n",
    "                            for d in artist_details: \n",
    "                                if art_has_auth_place == None or art_has_auth_date == None: \n",
    "                                    if 'id' in d and str(d['id']) not in null_values: \n",
    "                                        artist_id = d['id']\n",
    "                                        if artist_id in artists_with_place: \n",
    "                                          #  print(\"artist has place: \", artist_id)\n",
    "                                            art_has_auth_place = True\n",
    "                                        if artist_id in artists_with_date: \n",
    "                                          #  print(\"artist has date: \", artist_id)\n",
    "                                            art_has_auth_date = True\n",
    "                                        \n",
    "                                       \n",
    "                        if art_has_auth_date == True: \n",
    "                            tate_artist_date_count+=1\n",
    "                        if art_has_auth_place == True: \n",
    "                            tate_artist_place_count+=1\n",
    "                                \n",
    "                except Exception as e: \n",
    "                    print(f\"Error reading {file}: {e}\")\n",
    "                    files_crashed+=1\n",
    "                print(\"files processed: \", count_files)\n",
    "\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    print(\"total time: \", t)\n",
    "    print(\"files processed: \", count_files, \" File crashed: \", files_crashed)\n",
    "    result_list = [\"Tate\", artwork_count, tate_art_date_count, tate_art_place_count, 0, tate_artist_count, tate_artist_date_count, tate_artist_place_count, 0, 0]\n",
    "    print(\"Result: list with artwork_count, tate_art_date_count, tate_art_place_count, tate_artist_count, tate_artist_date_count, tate_artist_place_count, artist wd or ulan\")\n",
    "\n",
    "    count_list = [\"Tate\", artwork_count]\n",
    "    prop_list = [\"Tate\"]\n",
    "    results = result_list[2:]\n",
    "    for number in results: \n",
    "        p = pprint_prop(number, artwork_count, count_list, prop_list)\n",
    "    print(\"count_list: \", count_list)\n",
    "    print(\"prop_list: \", prop_list)\n",
    "    return count_list, prop_list\n",
    "\n",
    "# Define the path to the 'artworks' folder\n",
    "tate_artworks_path = \"downloaded-data/collection-master/artworks\"\n",
    "\n",
    "# Count the total number of artworks\n",
    "tate_count, tate_prop = count_artworks(tate_artworks_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119086bb-91ad-448a-993a-e7b2648b011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Dataset', 'Artworks', 'With date', 'With place', 'With date and place', 'With author', 'With author with date', 'With author with place','With artworks aligned to Wikidata', 'With author aligned to Wikidata or ULAN']\n",
    "headers_prop = headers.copy()\n",
    "headers_prop.remove('Artworks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ddd6a-be04-4942-871e-8c8c82463046",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [headers, tate_count]\n",
    "res_prop = [headers_prop, tate_prop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491738a-72d8-46f4-b103-8f4f2670404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "with open('tate_res.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerow(tate_count)\n",
    "with open('tate_res_prop.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(headers_prop)\n",
    "    writer.writerow(tate_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86e01d-541d-4378-8950-1c1d2bf5a26a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
